# -*- coding: utf-8 -*-

"""
------------------------------------------------

describe: 
    main

base_info:
    __author__ = "PyGo"
    __time__ = "2025/7/3 23:13"
    __version__ = "v.1.0.0"
    __mail__ = "gaoming971366@163.com"
    __blog__ = "www.pygo2.top"
    __project__ = "quality-rag"

usage:

1ã€response_modeçš„é€‰é¡¹ï¼ŒæŽ§åˆ¶å¦‚ä½•å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•´åˆåˆ°æœ€ç»ˆå“åº”ä¸­ï¼š
    "compact" ï¼ˆé»˜è®¤ï¼‰: å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆå¹¶åŽä¸€æ¬¡æ€§ç”Ÿæˆå“åº”ã€‚
    "refine" : è¿­ä»£ä¼˜åŒ–ç­”æ¡ˆï¼ˆå…ˆå¯¹ç¬¬ä¸€ä¸ªæ–‡æ¡£ç”Ÿæˆå“åº”ï¼Œå†ç”¨åŽç»­æ–‡æ¡£ä¿®æ­£ï¼‰ã€‚
    "tree_summarize" : ç”¨æ ‘çŠ¶ç»“æž„æ±‡æ€»æ–‡æ¡£ï¼ˆé€‚åˆé•¿æ–‡æœ¬ï¼‰ã€‚
    "no_text" : ä»…è¿”å›žæ£€ç´¢åˆ°çš„æ–‡æ¡£èŠ‚ç‚¹ï¼Œä¸ç”Ÿæˆå›žç­”ã€‚
    "accumulate" : åˆ†åˆ«å¯¹æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆå›žç­”åŽæ‹¼æŽ¥ã€‚

design:

reference urls:

python version:
    python3


Enjoy the good life everydayï¼ï¼!
Life is short, I use python.

------------------------------------------------
"""

# ------------------------------------------------------------
# usage: /usr/bin/python main.py.py
# ------------------------------------------------------------
from deploy.utils import get_model_ai, get_model_embedding, get_vector_abs_path
from deploy.config import VECTOR_COLLECTION_NAME, TOP, CHUNK_SIZE, CHUNK_OVERLAP
from deploy.vector import VectorChromaDB
from deploy.ai import RAGHuggingFaceAI, RAGOllamaAI

from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings
import streamlit as st
import os


# æ¨¡åž‹é…ç½®
MODEL_EMBEDDING = get_model_embedding()
MODEL_AI = get_model_ai()


# ---------------------------------------------
# é…ç½®æœ¬åœ°å¤§æ¨¡åž‹ > HuggingFace LLM
# ---------------------------------------------
llm = RAGHuggingFaceAI().llm

# ------------------------------
# é…ç½®æœ¬åœ°HuggingFace Embeddingæ¨¡åž‹
# ------------------------------
embed_model = HuggingFaceEmbedding(model_name=MODEL_EMBEDDING)

# ------------------------------
# Llama-Index Coreå…¨å±€é…ç½®
# ------------------------------
Settings.llm = llm
Settings.embed_model = embed_model
Settings.chunk_size = CHUNK_SIZE
Settings.chunk_overlap = CHUNK_OVERLAP

# ------------------------------
# åŠ è½½æŒä¹…åŒ–çš„ChromaDBç´¢å¼•
# ------------------------------
db = VectorChromaDB(db_path=get_vector_abs_path(), collection_name=VECTOR_COLLECTION_NAME)
vector_store = ChromaVectorStore(chroma_collection=db.collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# ------------------------------
# å‘é‡åŠ è½½ && æŸ¥è¯¢å¼•æ“Ž
# ------------------------------
index = VectorStoreIndex.from_vector_store(vector_store=vector_store)
query_engine = index.as_query_engine(
    similarity_top_k=TOP,               # ç›¸ä¼¼ç»“æžœæ•°é‡
    response_mode="tree_summarize",     # å“åº”æ¨¡å¼ï¼Œè¯¦æƒ…è§usage
    streaming=False,                    # æµå¼è¾“å‡º
    verbose=False,                      # è¯¦ç»†è¾“å‡º
)

# ------------------------------
# web
# ------------------------------
st.title("ðŸ“– è´¨é‡å¤§Qæ™ºèƒ½é—®ç­”RAGç³»ç»Ÿ")
st.markdown("åŸºäºŽæ£€ç´¢å¢žå¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„é—®ç­”å·¥å…·ï¼Œæ— éœ€ä¸Šä¼ æ–‡ä»¶ï¼Œç›´æŽ¥æé—®å³å¯ï¼")
st.text("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
col1, col2 = st.columns([4, 1])  # ç¬¬ä¸€åˆ—å®½åº¦å 4/5ï¼Œç¬¬äºŒåˆ—å 1/5
with col1:
    question = st.text_input(
        label="é—®é¢˜ï¼š",
        label_visibility="collapsed",
        placeholder="ä¾‹å¦‚ï¼šwgetå‘½ä»¤å¯ä»¥åšä»€ä¹ˆï¼Ÿ"
    )
with col2:
    submit_button = st.button("æäº¤")

if question and submit_button:
    print('>'*55 + 'start')
    response = query_engine.query(question)
    print(f"é—®é¢˜: {question}")
    print(f"å›žç­”: {response.response}")
    print('<'*55 + 'end')
    # responseå¯¹è±¡
    print(f"response.response: {response.response}")  # str	ç”Ÿæˆçš„ç­”æ¡ˆæ–‡æœ¬ï¼ˆæœ€å¸¸ç”¨ï¼‰
    print(f"response.source_nodes: {response.source_nodes}")  # List[NodeWithScore]	æ£€ç´¢åˆ°çš„æºèŠ‚ç‚¹ï¼ŒåŒ…å«æ–‡æ¡£ç‰‡æ®µå’Œç›¸ä¼¼åº¦å¾—åˆ†
    print(f"response.metadata: {response.metadata}")  # dict	å…ƒæ•°æ®ï¼ˆå¦‚æ¨¡åž‹åç§°ã€æ£€ç´¢å‚æ•°ç­‰ï¼‰
    print(f"response.get_formatted_sources(): {response.get_formatted_sources()}")  # str	æ ¼å¼åŒ–åŽçš„å‚è€ƒæ¥æºï¼ˆåŒ…å«æ–‡æœ¬å’Œå‡ºå¤„ï¼‰

    # æ˜¾ç¤ºç­”æ¡ˆ
    st.subheader("å›žç­”ï¼š")
    st.text(response.response)
    # æ˜¾ç¤ºå‚è€ƒæ¥æº
    st.subheader("å‚è€ƒå†…å®¹ï¼š")
    v_documents = []
    for i, doc in response.metadata.items():
        if doc.get("source") not in v_documents:
            v_documents.append(doc.get("source"))
            st.text(os.path.basename(doc.get("source")))


